{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ch2-summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. 신경망과의 첫 만남 (코드 동작 원리 개괄)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 텐서, 텐서연산, 미분, 경사하강법  \n",
    ":: MNIST(손글씨 샘플 데이터세트?)  \n",
    ":: 용어정리 -> 분류=클래스, 인풋=샘플, 결과값=레이블  \n",
    "\n",
    "- 케라스API로 MNIST 데이터세트 예제  \n",
    ":: 훈련할때는 훈련용데이터로, 테스트할땐 테스트데이터로  \n",
    ":: 용어정리 -> 네트워크=모델  \n",
    ":: 코드) 인풋을 512개 결과값으로 반환 -> 이전 레이어에서 받아서 10개 출력으로 반환  \n",
    ":: 코드) softmax 를 거쳐서 10개 결과 출력 -> 제일 높은 확률값을 반환  \n",
    "\n",
    "- 컴파일단계  \n",
    ":: 손실함수 'categorical_crossentoropy' 를 이용해서~  \n",
    ":: 옵티마이저는 rmsprop를 사용하겠습니다~  \n",
    ":: 메트릭스 정확도는~  \n",
    "\n",
    "- 전처리 단계  \n",
    ":: 보통 딥러닝에서는 층을 만들고 그 층에 맞게 데이터를 가공  \n",
    ":: reshape 함수 등으로~  \n",
    "\n",
    "- 학습실행  \n",
    ":: 컴파일 한다음 fit 함수로~  \n",
    ":: 학습이 진행될수록 손실함수가 줄어듬~  \n",
    ":: 정확도는 점점 올라감~  \n",
    "\n",
    "- 학습 결과에 대한 테스트  \n",
    ":: evaluate 함수로~~ -> 평가  \n",
    "\n",
    "- 오버피팅?  \n",
    ":: 훈련샘플을 통해 나온 결과값.. 하지만 테스트샘플은 그만큼 안나오는 현상  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 신경망을 위한 데이터표현 (용어 정리)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 텐서\n",
    "\n",
    "- 스칼라\n",
    "\n",
    "- 배열, 벡터\n",
    "\n",
    "- 백터를 말할떄의 차원과 텐서를 말할떄의 차원은 다름!!\n",
    "\n",
    "- 행렬\n",
    "\n",
    "- 고차원텐서\n",
    "\n",
    "- 축의 갯수 ..?  \n",
    ":: x, y ,z ... 등의 갯수  \n",
    ":: 랭크? -> 디멘션!!  \n",
    ":: 벡터는 직선, 행렬은 평면  \n",
    ":: 성분이란, 벡터 하나를 기준으로 봤을때 각 인덱스에 대한 의미  \n",
    ":: 크기란,  \n",
    "\n",
    "- 넘파이로 텐서 조작 ~\n",
    "\n",
    "- 배치데이터 ~  \n",
    ":: 전체데이터를 배치 단위로 나눠서 데이터 처리 진행  \n",
    ":: 순차적으로 나눠서 학습진행~ 랜덤으로 학습진행~ (설정하기 나름)  \n",
    ":: 보통 첫번째 차원축을 배치축이라고함~   \n",
    "\n",
    "- 텐서의 실제사례  \n",
    ":: 벡터데이터, 시계열, 이미지, 동영상  \n",
    "\n",
    "- 벡터데이터  \n",
    ":: 대부분의경우 벡터데이터에 해당  \n",
    ":: 첫번째축은 샘플축 두번째는 특성축  \n",
    ":: 예) 우편번호~  \n",
    ":: 예) 단어횟수카운팅~  \n",
    "\n",
    "- 시계얼데이터  \n",
    ":: ~  \n",
    "\n",
    "- 이미지데이터  \n",
    ":: ~  \n",
    "\n",
    "- 비디오데이터  \n",
    ":: ~  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3. 텐서 연산 (신경망의 톱니바퀴)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 각각의 텐서들을 어떻게 연산할것인가?  \n",
    "\n",
    "- Dense..?  \n",
    "\n",
    "- sigmoid? (활성함수)  \n",
    ":: 0을 기준으로 로그함수와 같은 모양이 나오는~  \n",
    ":: 다른층으로 보내기전에 한번 더 처리해주는~  \n",
    ":: 예를들어 전압~~ 일정전압이상이면 1로 판단하는~  \n",
    ":: 단점) 값이 증가할수록 특정값으로 수렴하는~  \n",
    ":: S 자로 나타나는 함수면 ~ ?  \n",
    "\n",
    "- relu..?  \n",
    ":: 0보다 작을때는 0으로 판단하고 0 보다 크면 자기값으로~  \n",
    "::  \n",
    "\n",
    "- 원소별연산..?  \n",
    ":: relu 함수에 대한 구현..? (비슷하게 구현~)  \n",
    ":: 다차원배열이라도 텐서끼리 연산 가능~  \n",
    ":: 차원이 달라도 연산가능? (누락부분은 패딩을 처리~)  \n",
    "\n",
    "- 브로드캐스팅  \n",
    ":: 축이랑 갯수가 안맞을때 연산하는 방법~  \n",
    ":: 큰 텐서에 맞도록 작은 텐서가 맞춰주고, 작은 텐서가 새 축을 따라서 반복됨~  \n",
    "\n",
    "- 텐서점곱  \n",
    ":: 스칼라곱이 아님, 행렬곱으로 생각~  \n",
    ":: \n",
    "\n",
    "- 텐서 크기변환  \n",
    ":: 열과 행을 재배열~  \n",
    ":: 전치..?  \n",
    "\n",
    "- 딥러닝의 기하학적 해석  \n",
    ":: 고차원 공간에서 복잡한 기하학적 변환을~  \n",
    ":: 종이공을 펼치는 것이 머신러닝이 하는일~  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4. 그래디언트 기반 최적화 (신경망의 엔진)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 신경망은 입력데이터를 다음과 같이 변환함  \n",
    ":: `relu(dot(W, input + b)`  \n",
    ":: W 는 가중치, b 는 바이어스(외부요인)  \n",
    ":: ex) 가중치는 공부노력 머리가좋은건 +a  \n",
    ":: 모델을 어떻게 정의하는가 에 대한 수식  \n",
    ":: 피드백 신호에 따라 가중치가 점진적으로 조정됨 (이런 과정을 훈련이라고부름)  \n",
    ":: * 가중치뿐만아니라 바이어스도 업데이트 됨!!  \n",
    "\n",
    "- 훈련샘플에 대한 반복루프  \n",
    ":: 참고) 1단계 -> 2단계 -> 3단계 -> 4단계  \n",
    ":: \n",
    "\n",
    "- 미분  \n",
    "\n",
    "- 텐서연산의 변화율을 그래디언트 라고 함  \n",
    ":: 미분을 통한~  \n",
    ":: 특정 좌표에 대한 변화율(기울기)를 추출하는~  \n",
    "\n",
    "- loss function (cost function)  \n",
    ":: 어떤 값이 97 이다 라고 예측되는데 신제 값에 대한 차이를 표현하는 방식 (뺄셈이나 제곱 등으로)  \n",
    ":: 목적에 따라서 선택하는 함수~  \n",
    "\n",
    "- 확률적 경사하강법  \n",
    ":: 손실함수의 값이 가장 작아지는 지점  \n",
    ":: 기울기가 0인부분을 찾는~  \n",
    ":: 역방향패스? 미분떄문에.. 손실함수를 역방향으로 역산?  \n",
    "\n",
    "-  back propagation ?   \n",
    ":: 왜하는가? 맨 처음 가졌던 특징들이 각 레이어를 거치면서 희미해져가는데 그걸 back propagation 을 통해서 살려내는 느낌~  \n",
    ":: 다중 퍼셈트론의 오차 수정? 출력층부터 시작해서 레이어를 거쳐온 순서대로 역산하는~  \n",
    "\n",
    "- 예측값을 찾아가는 과정?  \n",
    ":: 오차함수의 기울기가 0 인 부분을 조금씩 이동하면서 찾아냄  \n",
    ":: 조금씩 찾아가면 성능문제.. 보폭이 너무크면 못찾아냄..  \n",
    ":: \n",
    "\n",
    "- 지역최소값? 전역최소값?  \n",
    ":: 모멘텀? 현재 기울기값과 과거 현재 속도를 함께 고려해서 각 단계에서 공을 움직임  \n",
    "::  \n",
    "\n",
    "- 변화율 연결 역전파 알고리즘  \n",
    ":: 네트워크를 여러개의 함수로 표현  \n",
    ":: 연쇄법칙, 이 함수들을 미분을 하면 나오는 함수들을 ~  \n",
    ":: 각 파라미터가 기여한 정도를 계산~  \n",
    ":: 특성공학이 필요없는 이유가 역전파를 활용하기 때문에~!!  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5. 첫번째 예제 다시 살펴보기  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 에포크?  \n",
    ":: 전체 데이터를 몇번 반복할것인가? (배치는 전체 안에서 몇개로 나눌것인가)  \n",
    "::  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6. 요약"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 학습이란~\n",
    "\n",
    "- 네트워크 , 파라미터 , \n",
    "\n",
    "- 전체 학습 과정은 신경망이 미분가능한 텐서연산으로 연결되어 있기 때문에 ~\n",
    "\n",
    "- 다음장부터는 손실과 옵티마이저에 대한 ~\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
