{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (번외) 딥러닝 첫걸음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 과적합..?\n",
    "\n",
    "- 과적합과 싸우기..?  \n",
    "  reguladation + validation\n",
    "\n",
    "- 지도학습 / 비지도학습 / 강화학습 \n",
    "\n",
    "- 분류와 회귀  \n",
    "  분류 : \"범주\" 가 정답으로 주어지고  \n",
    "  회귀 : \"값\" 이 정답으로 주어짐\n",
    "\n",
    "- 딥러닝의 수학적 표현  \n",
    "  뉴런과 뉴런 사이에서 신호를 주고받으면서 동작하는 신경세포  \n",
    "  이를 수학적으로 생각하면, 각 입력값들에 대한 가중치 연산을 합산하여 하나의스칼라로 출력을 내뱉는~  \n",
    "  (입력 여러개 => 스칼라 출력 하나)\n",
    "  \n",
    "- 신경세포 == 신경망  \n",
    "  뇌 == 노드  \n",
    "  신경세포연결 == 연결가중치\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- 단층/다층(얕은/심층) 신경망\n",
    "\n",
    "- 하나하나 다수입력을 스칼라출력으로 변환하는 과정... 번거로움..  \n",
    "  가중합 계산식을 행렬식으로 변환할수있음! (간편!)\n",
    "  \n",
    "- 델타 규칙..?  \n",
    "  단층신경망에서 가중치를 갱신시켜주는 규칙!!  \n",
    "  어떤 입력노드가 출력노드의 오차에 기여했다면,  \n",
    "  두 노드의 연결 가중치는 해당 입력노드의 출력과 출력노드의 오차에 비례해 조절한다.\n",
    "  \n",
    "- SDG(경사하강법)..?  \n",
    "  가중치를 그때그때 바로 조절하는 방법\n",
    "\n",
    "- 배치 ..?  \n",
    "  가중치를 한번에 갱신\n",
    "  \n",
    "- 미니배치..?  \n",
    "  전체에서 일부만 골라 배치방식 학습  \n",
    "  보통 미니배치로 사용함\n",
    "  \n",
    "- 단층신경망의 한계..?  \n",
    "  선형분리가 가능한 문제만 해결할수있음!  \n",
    "  선형이 아닌 분류문제에서는 사용할수없음\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 다층신경망 학습\n",
    "\n",
    "- 다층신경망이란..?\n",
    "\n",
    "- 학습은 신경망에 정보를 저장할수있는 거의 유일한방법\n",
    "\n",
    "- 역전파 알고리즘..?  \n",
    "  은닉노드의 오차는 델타를 역전파시켜(미분해서) 얻은 가중합으로 구함  \n",
    "  이 값에 활성함수의 도함수값을 곱해 해당노드의 델타를 구함\n",
    "\n",
    "- 역전파 동작원리..?  \n",
    "  예측값-실제값 = 오차값  \n",
    "  앞으로갈때는 입력으로 계산해서~  \n",
    "  뒤로갈때는, 오차값을 적용한 값에 가중치를 역으로 계싼해서~~\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 모멘텀..?\n",
    "\n",
    "- 비용함수..?\n",
    "\n",
    "- 역전파로 가중치 갱신..?  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 신경망과 분류..?\n",
    "\n",
    "- 이진분류..?  \n",
    "  yes or no 로 대답할수있는 문제\n",
    "\n",
    "- 이진분류 신경망의 학습과정  \n",
    "  출력층은 1개 + 활성함수는 시그모이드\n",
    "  \n",
    "- 다범주 분류..?  \n",
    "  3개 이상의 범주로 분류하는 문제~\n",
    "\n",
    "- 원핫인코딩을 활용해서~\n",
    "\n",
    "- 소프트맥스함수..?  \n",
    "  다른 출력노드의 가중합도 고려해서 동작하는 활성화함수~  \n",
    "  각쳘력노드의 출력을 0~1 로 제한하고, 출력노드들의 출력합을 항상 1이 되도록~ (결국 확률이 제일높은거 나오도록)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 딥러닝..?  \n",
    "  심층신경망(은닉층이2개이상인) 신경망으로 구성된 네트워크.. 머신러닝기법..!!\n",
    "\n",
    "- 심층신경망 성능 개선..?  \n",
    "  역전파알고리즘으로 심층신경망을 학습시킬때 겪는 어려움.. 미분반복으로 인한 정보 소실.. 과적합.. 많은계산량..\n",
    "\n",
    "- 그래디언트 소실..?  \n",
    "  역전파 동작에서 출력층에서 멀어질수록 신경망의 출력오차가 반영되지않는 현상  \n",
    "  relu 함수로 어느정도 해결..?\n",
    "\n",
    "- 과적합..?  \n",
    "  은닉츠이 늘어나면서 모델이 복잡해져서.. 과적합문제발생..  \n",
    "  많은 은닉층이 모든특성을 다 고려하다보니 그 데이터세트에만 특화되어버리는..  \n",
    "  드롭아웃기법 등으로 어느정도해결..?  \n",
    "  드롭아웃 출력을 보상해주기위해 (활성화안된.. 드롭아웃된노드에 대한) 보상을 적용..?\n",
    "\n",
    "- 많은 계산량..?  \n",
    "  좋은 gpu 사용~!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(질문)\n",
    "\n",
    "- 역전파알고리즘 사용이유..?  \n",
    "  가중치업데이트!!\n",
    "\n",
    "- 미분가능한 함수..?  \n",
    "  relu 는 미분가능하지 않는 함수..?  \n",
    "  relu 자체는 미분불가능이지만, (수식적으로는 미분불능인데) 어차피 0을 미분하면 0이 되므로..??\n",
    "\n",
    "- 모든 텐서연산은 미분가능한 이유..?  \n",
    "  행렬 det 이 0 일때..?  \n",
    "  행렬미분 어떻게..? 행렬식..?  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
