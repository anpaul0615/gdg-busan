{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ch5-summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1. 합성곱 신경망 소개 \n",
    "\n",
    "- 합성곱신경망 이라는 딥러닝모델 ..?\n",
    "\n",
    "- CNN 에서는 층이 많아지는.. N차원 벡터로 처리되는게 특징..\n",
    "\n",
    "- (코드설명)  \n",
    "  2차원 합성곱 층 여러개를 쌓아서  \n",
    "  Conv@D : 3 * 3 ..? 이미지를 9개 격자로 분할해서 학습하는~  \n",
    "  MaxPooling2D : 과대적합을 줄이기 위해서~ 다운샘플링~ \n",
    "\n",
    "- 일단 컨브넷은 image_height, width, channels 크기의 입력텐서를 사용함  \n",
    "  높이와 넓이 차원은 네트워크가 깊어질수록 작아지는 경항~ (테두리 패딩처리로인해 점점 소실되는~)\n",
    "  \n",
    "- 이미지를 conv2d + maxpolling 으로 처리한다음 맨마지막 층을 dense 층으로 구성하여 분류 시작 \n",
    "\n",
    "- 앞의장에서의 예제 (dense 기반) 와 conv넷 기반 예제의 성능비교 (64% 차이!!)\n",
    "\n",
    "\n",
    "### 5.1.1 합성곱 연산 \n",
    "\n",
    "- 일반적인 완전연결층 모델로는 이미지데이터를 전체를 한꺼번에 학습하지만,  \n",
    "  cnn에서는 지역별로 나눠서 지역패턴을 학습함 => 2d차원에서 필터를 입력으로 처리해서 학습~~  \n",
    "\n",
    "- 쪼개서 학습하면, 이미 앞에서 학습을 한것을 나중에 다른층에서도 그 학습값을 사용할수있음  \n",
    "  왼쪽에서 학습한 패턴으로 오른쪽부분의 패턴을 같이 학습할수있음\n",
    "\n",
    "- 평행이동을 하더라도 같은 대상으로 인식한다는 아이디어!!\n",
    "\n",
    "- 공간적계층구조..?  \n",
    "  각 층에서의 인식하는 특징들을 모아서 데이터를 최종적으로 인식하는~~  \n",
    "  첫번째충은 질감을뽑아내고 두번째층에서는 모양을뽑아내고 세번째층은 ~~~ 마지막층에서 고양이라는걸 분류함~~\n",
    "  \n",
    "- 응답맵..? 출력맵..? 특성맵..?\n",
    "\n",
    "- 필터를 씌워서 특정 지역에 대한 특징을 추출 + 그 부분특징에 대해서만 학습함 + 나머지 층들에서 반복수행\n",
    "\n",
    "- 경계문제..? 소실시키지않으려면..?  \n",
    "  패딩을 사용해서~  \n",
    "  valid 패딩 => 패딩을 사용하지 않겠다 ~  \n",
    "  same 패딩 => 입력과 동일한 높이와 넓이의 패딩~\n",
    "\n",
    "- 필터의 의미..?  \n",
    "  이미지 특정지역에 대한 일련의 연산..?  \n",
    "  특정 연산을 하면 스칼라값이 결과로 나오게됨 => 이걸 32번 64번 반복한다는 의미 (이걸 깊이라고 함)\n",
    "\n",
    "\n",
    "### 5.1.2 최대 풀링 연산 \n",
    "\n",
    "- 합성곱 스트라이드..? => 슬라이딩 윈도우의 이동거리단위  \n",
    "  스트라이드가 커질수록 출력 크기가 줄어듬  \n",
    "  2배 배수로 다운샘플링됨..\n",
    "\n",
    "- 맥스풀링을 사용하는 이유..?  \n",
    "  맥스풀링 : 강제적으로 특성맵을 다운샘플링 하는 역할  \n",
    "  맥스풀링은 2 * 2 윈도우와 스트라이드 2 를 사용해서 전체크기를 다운샘플링하는 방식으로 동작함  \n",
    "  반면 합성곱스트라이드는 3 * 3 윈도우와 스트라이드1 을 사용함  \n",
    "  \n",
    "- 맥스풀링이 아닌 합성곱스트라이드는 공간적계층구조를 학습하기 어려움  \n",
    "  테두리가 줄어드는 방식이므로 같은영역을 반복학습할수있으므로 과대적합 발생가능성 높음\n",
    "\n",
    "- \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2. 소규모 데이터셋에서 밑바닥부터 컨브넷 훈련하기 \n",
    "\n",
    "- 데이터셋이 별로없을때 컨브넷을 훈련하는 방법 (수백개~수만개 정도)\n",
    "\n",
    "- 처음부터 새로운모델을 훈련한다음 => 이미만들어진 모델을 기반으로 훈련하는 방법\n",
    "\n",
    "- 비전에서 과대적합 줄이는방법..? => 데이터 증식!! (이미지를 회전시키는 등)\n",
    "\n",
    "- 핵심적인 기술 2가지  \n",
    "  사전훈련된 네트워크로 특성을 추출하는방법  \n",
    "  사전훈련된 ~ 에서 튜닝하는방법  \n",
    "\n",
    "\n",
    "### 5.2.1 작은 데이터셋 문제에서 딥러닝의 타당성 \n",
    "\n",
    "- 샘플이 많다는것의 의미..?\n",
    "\n",
    "- 컨브넷은 평행이동에 제한이없기때문에~\n",
    "\n",
    "- 딥러닝모델은 태생적으로 다목적으로 ~\n",
    "\n",
    "\n",
    "### 5.2.2 데이터 내려받기 \n",
    "\n",
    "- 캐글 고양이/강아지 훈련용 데이터세트 준비\n",
    "\n",
    "\n",
    "### 5.2.3 네트워크 구성하기 \n",
    "\n",
    "- 특성 추출기 + 분류기\n",
    "\n",
    "\n",
    "### 5.2.4 데이터 전처리 \n",
    "\n",
    "- 케라스에서 제공하는 api 로 데이터 전처리 (이미지사이즈 통일 등)\n",
    "\n",
    "- 제너레이터..?  \n",
    "  데이터 제어구조를 좀더 잘게 쪼개서 관리할수있는~  \n",
    "  yield 양보하다~  \n",
    "\n",
    "- ImageGenerator.. fit_generator ..  \n",
    "  제네레이터 기반 모델 API 사용해서 메모리 최적화~\n",
    " \n",
    "\n",
    "### 5.2.5 데이터 증식 사용하기 \n",
    "\n",
    "- 과대적합 발생.. 데이터샘플수가 부족함.. => 데이터개수를 증식!!\n",
    "\n",
    "- 기존 데이터를 로테이션.. 너비.. 배율.. 반전.. 등으로 조금씩 다르게 노이즈를 섞어서 ~\n",
    "\n",
    "- 노이즈가 들어가더라도 과적합이 발생할수있음 => 드롭아웃 층을 분류기에 추가해서 ~\n",
    "\n",
    "- \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3. 사전 훈련된 컨브넷 사용하기 \n",
    "\n",
    "- 연구자들이 연구한 사전훈련된 네트워크를 활용하는 ~  \n",
    "  다른 머신러닝보다 딥러닝의 장점!!\n",
    "\n",
    "- 특성을 추출하는 방법 / 미세조정하는 방법\n",
    "\n",
    "\n",
    "### 5.3.1 특성 추출 \n",
    "\n",
    "- 사전훈련된 합성곱 기분 층 + 사전훈련된 분류기\n",
    "\n",
    "- 분류기는 우리 목적에 맞게 다시 구성하고,  \n",
    "  특성을 학습한 층은 이미 훈련되어있는 훈련된 합성곱 기반 층만 사용함\n",
    "\n",
    "- 나중에 튜닝 단계에서 동결을 풀게되는데, 어떤층을 푸는지에 대한 기준은..? => 맨 마지막 층만!! \n",
    "\n",
    "\n",
    "### 5.3.2 미세 조정 \n",
    "\n",
    "- 모델의 일부를 미세조정  \n",
    "  미세조정 대상 층만 동결을 풀고 부분적으로 재학습 실행\n",
    "\n",
    "- 먼저 분류기를 학습시킨다음에 타겟 층을 미세조정하고 ~\n",
    "\n",
    "- 왜 더 많은 층을 미세조정하지않을까..?\n",
    "\n",
    "\n",
    "### 5.3.3 정리 \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4. 컨브넷 학습 시각화 \n",
    "\n",
    "### 5.4.1 중간층의 활성화 시각화하기 \n",
    "\n",
    "### 5.4.2 컨브넷 필터 시각화하기 \n",
    "\n",
    "### 5.4.3 클래스 활성화의 히트맵 시각화하기 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
